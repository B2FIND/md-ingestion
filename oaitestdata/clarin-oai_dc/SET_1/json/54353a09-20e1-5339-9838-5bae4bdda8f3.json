{
    "Contact": [
        "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)"
    ],
    "DiscHierarchy": [
        "1.4",
        "Humanities",
        "Linguistics"
    ],
    "Discipline": "Linguistics",
    "Format": [
        "downloadable_files_count: 11",
        "text/plain; charset=utf-8",
        "application/octet-stream"
    ],
    "Language": [
        "Czech",
        "Slovak",
        "Slovenian",
        "Croatian",
        "Danish",
        "Swedish",
        "Norwegian"
    ],
    "MetaDataAccess": "https://clarin-pl.eu/oai/request?verb=GetRecord&metadataPrefix=oai_dc&identifier=oai:lindat.mff.cuni.cz:11234/1-1970",
    "MetadataAccess": [
        "oai:lindat.mff.cuni.cz:11234/1-1970"
    ],
    "PID": "http://hdl.handle.net/11234/1-1970",
    "PublicationTimestamp": "2017-01-28T11:59:59Z",
    "PublicationYear": [
        "2017"
    ],
    "Publisher": [
        "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)"
    ],
    "RelatedIdentifier": [
        "info:eu-repo/grantAgreement/EC/H2020/644402",
        "http://web.science.mq.edu.au/~smalmasi/vardial4/pdf/VarDial26.pdf"
    ],
    "ResourceType": [
        "toolService"
    ],
    "Rights": [
        "GNU General Public License 2 or later (GPL-2.0)",
        "http://opensource.org/licenses/GPL-2.0",
        "PUB"
    ],
    "author": [
        "\u017dabokrtsk\u00fd, Zden\u011bk",
        "Zeman, Daniel",
        "Mare\u010dek, David",
        "Rosa, Rudolf"
    ],
    "fulltext": "oai:lindat.mff.cuni.cz:11234/1-1970;2017-11-09T14:21:55Z;hdl_11858_00-097C-0000-0001-486F-D;hdl_11858_00-097C-0000-0001-4877-A;Slavic Forest, Norwegian Wood (scripts);Rosa, Rudolf;Zeman, Daniel;Mare\u010dek, David;\u017dabokrtsk\u00fd, Zden\u011bk;parsing;dependency parser;universal dependencies;cross-lingual parsing;Tools and scripts used to create the cross-lingual parsing models submitted to VarDial 2017 shared task (https://bitbucket.org/hy-crossNLP/vardial2017), as described in the linked paper. The trained UDPipe models themselves are published in a separate submission (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1971).\r\n\r\nFor each source (SS, e.g. sl) and target (TT, e.g. hr) language,\r\nyou need to add the following into this directory:\r\n\r\n- treebanks (Universal Dependencies v1.4):\r\nSS-ud-train.conllu\r\nTT-ud-predPoS-dev.conllu\r\n\r\n- parallel data (OpenSubtitles from Opus):\r\nOpenSubtitles2016.SS-TT.SS\r\nOpenSubtitles2016.SS-TT.TT\r\n!!! If they are originally called ...TT-SS... instead of ...SS-TT...,\r\nyou need to symlink them (or move, or copy) !!!\r\n\r\n- target tagging model\r\nTT.tagger.udpipe\r\n\r\nAll of these can be obtained from https://bitbucket.org/hy-crossNLP/vardial2017\r\n\r\n\r\nYou also need to have:\r\n- Bash\r\n- Perl 5\r\n- Python 3\r\n- word2vec (https://code.google.com/archive/p/word2vec/); we used rev 41 from 15th Sep 2014\r\n- udpipe (https://github.com/ufal/udpipe); we used commit 3e65d69 from 3rd Jan 2017\r\n- Treex (https://github.com/ufal/treex); we used commit d27ee8a from 21st Dec 2016\r\n\r\n\r\nThe most basic setup is the sl-hr one (train_sl-hr.sh):\r\n- normalization of deprels\r\n- 1:1 word-alignment of parallel data with Monolingual Greedy Aligner\r\n- simple word-by-word translation of source treebank\r\n- pre-training of target word embeddings\r\n- simplification of morpho feats (use only Case)\r\n- and finally, training and evaluating the parser\r\n\r\nBoth da+sv-no (train_ds-no.sh) and cs-sk (train_cs-sk.sh) add some cross-tagging, which seems to be useful only in\r\nspecific cases (see paper for details).\r\nMoreover, cs-sk also adds more morpho features, selecting those that\r\nseem to be very often shared in parallel data.\r\n\r\nThe whole pipeline takes tens of hours to run, and uses several GB of RAM, so make sure to use a powerful computer.;2017-01-28;toolService;http://hdl.handle.net/11234/1-1970;ces;slk;slv;hrv;dan;swe;nor;info:eu-repo/grantAgreement/EC/H2020/644402;http://web.science.mq.edu.au/~smalmasi/vardial4/pdf/VarDial26.pdf;GNU General Public License 2 or later (GPL-2.0);http://opensource.org/licenses/GPL-2.0;PUB;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;application/octet-stream;text/plain; charset=utf-8;downloadable_files_count: 11;Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)",
    "group": "clarin",
    "groups": [
        {
            "name": "clarin"
        }
    ],
    "name": "54353a09-20e1-5339-9838-5bae4bdda8f3",
    "notes": [
        "Tools and scripts used to create the cross-lingual parsing models submitted to VarDial 2017 shared task (https://bitbucket.org/hy-crossNLP/vardial2017), as described in the linked paper. The trained UDPipe models themselves are published in a separate submission (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1971).\r\n\r\nFor each source (SS, e.g. sl) and target (TT, e.g. hr) language,\r\nyou need to add the following into this directory:\r\n\r\n- treebanks (Universal Dependencies v1.4):\r\nSS-ud-train.conllu\r\nTT-ud-predPoS-dev.conllu\r\n\r\n- parallel data (OpenSubtitles from Opus):\r\nOpenSubtitles2016.SS-TT.SS\r\nOpenSubtitles2016.SS-TT.TT\r\n!!! If they are originally called ...TT-SS... instead of ...SS-TT...,\r\nyou need to symlink them (or move, or copy) !!!\r\n\r\n- target tagging model\r\nTT.tagger.udpipe\r\n\r\nAll of these can be obtained from https://bitbucket.org/hy-crossNLP/vardial2017\r\n\r\n\r\nYou also need to have:\r\n- Bash\r\n- Perl 5\r\n- Python 3\r\n- word2vec (https://code.google.com/archive/p/word2vec/); we used rev 41 from 15th Sep 2014\r\n- udpipe (https://github.com/ufal/udpipe); we used commit 3e65d69 from 3rd Jan 2017\r\n- Treex (https://github.com/ufal/treex); we used commit d27ee8a from 21st Dec 2016\r\n\r\n\r\nThe most basic setup is the sl-hr one (train_sl-hr.sh):\r\n- normalization of deprels\r\n- 1:1 word-alignment of parallel data with Monolingual Greedy Aligner\r\n- simple word-by-word translation of source treebank\r\n- pre-training of target word embeddings\r\n- simplification of morpho feats (use only Case)\r\n- and finally, training and evaluating the parser\r\n\r\nBoth da+sv-no (train_ds-no.sh) and cs-sk (train_cs-sk.sh) add some cross-tagging, which seems to be useful only in\r\nspecific cases (see paper for details).\r\nMoreover, cs-sk also adds more morpho features, selecting those that\r\nseem to be very often shared in parallel data.\r\n\r\nThe whole pipeline takes tens of hours to run, and uses several GB of RAM, so make sure to use a powerful computer."
    ],
    "oai_identifier": [
        "oai:lindat.mff.cuni.cz:11234/1-1970"
    ],
    "oai_set": [
        "hdl_11858_00-097C-0000-0001-486F-D",
        "hdl_11858_00-097C-0000-0001-4877-A"
    ],
    "state": "active",
    "tags": [
        {
            "name": "parsing"
        },
        {
            "name": "dependency parser"
        },
        {
            "name": "universal dependencies"
        },
        {
            "name": "cross-lingual parsing"
        }
    ],
    "title": [
        "Slavic Forest, Norwegian Wood (scripts)"
    ],
    "url": ""
}