{
    "Contact": [
        "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)",
        "University of Amsterdam, ILLC"
    ],
    "DiscHierarchy": [
        "1.4",
        "Humanities",
        "Linguistics"
    ],
    "Discipline": "Linguistics",
    "Format": [
        "downloadable_files_count: 5",
        "text/plain; charset=utf-8",
        "application/x-gzip",
        "application/octet-stream"
    ],
    "Language": [
        "Czech",
        "English"
    ],
    "MetaDataAccess": "https://clarin-pl.eu/oai/request?verb=GetRecord&metadataPrefix=oai_dc&identifier=oai:lindat.mff.cuni.cz:11372/LRT-1671",
    "MetadataAccess": [
        "oai:lindat.mff.cuni.cz:11372/LRT-1671"
    ],
    "PID": "http://hdl.handle.net/11372/LRT-1671",
    "PublicationTimestamp": "2016-03-21T11:59:59Z",
    "PublicationYear": [
        "2016"
    ],
    "Publisher": [
        "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)",
        "University of Amsterdam, ILLC"
    ],
    "RelatedIdentifier": [
        "info:eu-repo/grantAgreement/EC/H2020/645452"
    ],
    "ResourceType": [
        "corpus"
    ],
    "Rights": [
        "Creative Commons - Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
        "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "PUB"
    ],
    "author": [
        "Stanojevic, Milos",
        "Bojar, Ond\u0159ej",
        "Jawaid, Bushra",
        "Kamran, Amir"
    ],
    "fulltext": "oai:lindat.mff.cuni.cz:11372/LRT-1671;2017-11-09T14:20:30Z;hdl_11858_00-097C-0000-0007-710A-A;hdl_11858_00-097C-0000-0007-710B-8;WMT16 Tuning Shared Task Models (Czech-to-English);Kamran, Amir;Jawaid, Bushra;Bojar, Ond\u0159ej;Stanojevic, Milos;WMT16;machine translation;tuning;baseline models;shared task;The item contains models to tune for the WMT16 Tuning shared task for Czech-to-English.\r\n\r\nCzEng 1.6pre (http://ufal.mff.cuni.cz/czeng/czeng16pre) corpus is used for the training of the translation models. The data is tokenized (using Moses tokenizer), lowercased and sentences longer than 60 words and shorter than 4 words are removed before training. Alignment is done using fast_align (https://github.com/clab/fast_align) and the standard Moses pipeline is used for training.\r\n\r\nTwo 5-gram language models are trained using KenLM: one only using the CzEng English data and the other is trained using all available English mono data for WMT except Common Crawl.\r\n\r\nAlso included are two lexicalized bidirectional reordering models, word based and hierarchical, with msd conditioned on both source and target of processed CzEng.;2016-03-21;corpus;http://hdl.handle.net/11372/LRT-1671;ces;eng;info:eu-repo/grantAgreement/EC/H2020/645452;Creative Commons - Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0);http://creativecommons.org/licenses/by-nc-sa/4.0/;PUB;application/x-gzip;application/x-gzip;application/x-gzip;application/octet-stream;application/octet-stream;text/plain; charset=utf-8;downloadable_files_count: 5;Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL);University of Amsterdam, ILLC;http://www.statmt.org/wmt16/tuning-task/",
    "group": "clarin",
    "groups": [
        {
            "name": "clarin"
        }
    ],
    "name": "85b5f97a-6028-5922-954d-eaa19a6fdd0d",
    "notes": [
        "The item contains models to tune for the WMT16 Tuning shared task for Czech-to-English.\r\n\r\nCzEng 1.6pre (http://ufal.mff.cuni.cz/czeng/czeng16pre) corpus is used for the training of the translation models. The data is tokenized (using Moses tokenizer), lowercased and sentences longer than 60 words and shorter than 4 words are removed before training. Alignment is done using fast_align (https://github.com/clab/fast_align) and the standard Moses pipeline is used for training.\r\n\r\nTwo 5-gram language models are trained using KenLM: one only using the CzEng English data and the other is trained using all available English mono data for WMT except Common Crawl.\r\n\r\nAlso included are two lexicalized bidirectional reordering models, word based and hierarchical, with msd conditioned on both source and target of processed CzEng."
    ],
    "oai_identifier": [
        "oai:lindat.mff.cuni.cz:11372/LRT-1671"
    ],
    "oai_set": [
        "hdl_11858_00-097C-0000-0007-710A-A",
        "hdl_11858_00-097C-0000-0007-710B-8"
    ],
    "state": "active",
    "tags": [
        {
            "name": "WMT"
        },
        {
            "name": "machine translation"
        },
        {
            "name": "tuning"
        },
        {
            "name": "baseline models"
        },
        {
            "name": "shared task"
        }
    ],
    "title": [
        "WMT16 Tuning Shared Task Models (Czech-to-English)"
    ],
    "url": ""
}