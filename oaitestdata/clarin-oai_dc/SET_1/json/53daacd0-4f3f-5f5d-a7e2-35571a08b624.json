{
    "Contact": [
        "Institute of Computer Science, Polish Academy of Sciences"
    ],
    "DiscHierarchy": [
        "1.4",
        "Humanities",
        "Linguistics"
    ],
    "Discipline": "Linguistics",
    "Format": [
        "text/plain; charset=utf-8",
        "application/octet-stream",
        "text/plain",
        "application/zip",
        "downloadable_files_count: 4",
        "application/pdf"
    ],
    "Language": [
        "Polish"
    ],
    "MetaDataAccess": "https://clarin-pl.eu/oai/request?verb=GetRecord&metadataPrefix=oai_dc&identifier=oai:clarin-pl.eu:11321/265",
    "MetadataAccess": [
        "oai:clarin-pl.eu:11321/265"
    ],
    "PID": "http://hdl.handle.net/11321/265",
    "PublicationTimestamp": "2016-05-29T11:59:59Z",
    "PublicationYear": [
        "2016"
    ],
    "Publisher": [
        "Institute of Computer Science, Polish Academy of Sciences"
    ],
    "ResourceType": [
        "toolService"
    ],
    "Rights": [
        "BSD 2 Clause",
        "https://opensource.org/licenses/BSD-2-Clause",
        "PUB"
    ],
    "author": [
        "Rychlik, Piotr"
    ],
    "fulltext": "oai:clarin-pl.eu:11321/265;2016-05-29T08:24:31Z;hdl_11321_3;hdl_11321_4;tokenizer;Rychlik, Piotr;tokenization;Tokenizer is a tool with wich one can design dedicated tokenizers for texts from some domain of interest.;2016-05-29;toolService;http://hdl.handle.net/11321/265;pol;BSD 2 Clause;https://opensource.org/licenses/BSD-2-Clause;PUB;text/plain; charset=utf-8;application/octet-stream;application/octet-stream;text/plain;application/zip;application/octet-stream;application/pdf;downloadable_files_count: 4;Institute of Computer Science, Polish Academy of Sciences",
    "group": "clarin",
    "groups": [
        {
            "name": "clarin"
        }
    ],
    "name": "53daacd0-4f3f-5f5d-a7e2-35571a08b624",
    "notes": [
        "Tokenizer is a tool with wich one can design dedicated tokenizers for texts from some domain of interest."
    ],
    "oai_identifier": [
        "oai:clarin-pl.eu:11321/265"
    ],
    "oai_set": [
        "hdl_11321_3",
        "hdl_11321_4"
    ],
    "state": "active",
    "tags": [
        {
            "name": "tokenization"
        }
    ],
    "title": [
        "tokenizer"
    ],
    "url": ""
}