<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <header>
    <identifier>oai:lindat.mff.cuni.cz:11234/1-2607</identifier>
    <datestamp>2018-07-02T22:05:49Z</datestamp>
    <setSpec>hdl_11858_00-097C-0000-0001-486F-D</setSpec>
    <setSpec>hdl_11858_00-097C-0000-0001-4877-A</setSpec>
  </header>
  <metadata>
    <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:doc="http://www.lyncode.com/xoai" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
      <dc:title>Corpus for training and evaluating diacritics restoration systems</dc:title>
      <dc:creator>N&#225;plava, Jakub</dc:creator>
      <dc:creator>Straka, Milan</dc:creator>
      <dc:creator>Haji&#269;, Jan</dc:creator>
      <dc:creator>Stra&#328;&#225;k, Pavel</dc:creator>
      <dc:subject>diacritical marks generation</dc:subject>
      <dc:subject>natural language correction</dc:subject>
      <dc:description>Corpus of texts in 12 languages. For each language, we provide one training, one development and one testing set acquired from Wikipedia articles. Moreover, each language dataset contains (substantially larger) training set collected from (general) Web texts. All sets, except for Wikipedia and Web training sets that can contain similar sentences, are disjoint. Data are segmented into sentences which are further word tokenized.&#13;
&#13;
All data in the corpus contain diacritics. To strip diacritics from them, use Python script diacritization_stripping.py contained within attached stripping_diacritics.zip. This script has two modes. We generally recommend using method called uninames, which for some languages behaves better. &#13;
&#13;
The code for training recurrent neural-network based model for diacritics restoration is located at https://github.com/arahusky/diacritics_restoration.</dc:description>
      <dc:date>2018-01-31</dc:date>
      <dc:type>corpus</dc:type>
      <dc:identifier>http://hdl.handle.net/11234/1-2607</dc:identifier>
      <dc:language>ces</dc:language>
      <dc:language>vie</dc:language>
      <dc:language>ron</dc:language>
      <dc:language>pol</dc:language>
      <dc:language>slk</dc:language>
      <dc:language>spa</dc:language>
      <dc:language>hrv</dc:language>
      <dc:language>gle</dc:language>
      <dc:language>lav</dc:language>
      <dc:language>hun</dc:language>
      <dc:language>fra</dc:language>
      <dc:language>tur</dc:language>
      <dc:rights>Creative Commons - Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</dc:rights>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:rights>PUB</dc:rights>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>text/plain; charset=utf-8</dc:format>
      <dc:format>downloadable_files_count: 13</dc:format>
      <dc:publisher>Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)</dc:publisher>
    </oai_dc:dc>
  </metadata>
</record>
