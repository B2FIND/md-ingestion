<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <header>
    <identifier>oai:clarin-pl.eu:11321/403</identifier>
    <datestamp>2017-06-28T09:14:07Z</datestamp>
    <setSpec>hdl_11321_3</setSpec>
    <setSpec>hdl_11321_4</setSpec>
  </header>
  <metadata>
    <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:doc="http://www.lyncode.com/xoai" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
      <dc:title>CorpoGrabber</dc:title>
      <dc:creator>Koco&#324;, Jan</dc:creator>
      <dc:subject>CorpoGrabber</dc:subject>
      <dc:subject>corpus</dc:subject>
      <dc:subject>acquiring</dc:subject>
      <dc:subject>web scraping</dc:subject>
      <dc:subject>corpora builder</dc:subject>
      <dc:description>CorpoGrabber: The Toolchain to Automatic Acquiring and Extraction of the Website Content&#13;
Jan Koco&#324;, Wroclaw University of Technology&#13;
&#13;
CorpoGrabber is a pipeline of tools to get the most relevant content of the website, including all subsites (up to the user-defined depth). The proposed toolchain can be used to build a big Web corpora of text documents. It requires only the list of the root websites as the input. Tools composing CorpoGrabber are adapted to Polish, but most subtasks are language independent. The whole process can be run in parallel on a single machine and includes the following tasks: downloading of the HTML subpages of each input page URL [1], extracting of plain text from each subpage by removing boilerplate content (such as navigation links, headers, footers, advertisements from HTML pages) [2], deduplication of plain text [2], removing of bad quality documents utilizing Morphological Analysis Converter and Aggregator (MACA) [3], tagging of documents using Wroc&#322;aw CRF Tagger (WCRFT) [4]. Last two steps are available only for Polish. The result is a corpora as a set of tagged documents for each website. &#13;
&#13;
References&#13;
[1] https://www.httrack.com/html/faq.html&#13;
[2] J. Pomikalek. 2011. Removing Boilerplate and Duplicate Content from Web Corpora. Ph.D. Thesis. Masaryk University, Faculcy of Informatics. Brno.&#13;
[3] A. Radziszewski, T. Sniatowski. 2011. Maca &#8211; a configurable tool to integrate Polish morphological data. Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation. Barcelona, Spain.&#13;
[4] A. Radziszewski. 2013. A tiered CRF tagger for Polish. Intelligent Tools for Building a Scientific Information Platform: Advanced Architectures and Solutions. Springer Verlag.</dc:description>
      <dc:date>2017-06-28</dc:date>
      <dc:type>toolService</dc:type>
      <dc:identifier>http://hdl.handle.net/11321/403</dc:identifier>
      <dc:language>N/A</dc:language>
      <dc:rights>GNU LGPL 3.0</dc:rights>
      <dc:rights>http://www.gnu.org/licenses/lgpl.html</dc:rights>
      <dc:rights>PUB</dc:rights>
      <dc:format>text/plain; charset=utf-8</dc:format>
      <dc:format>application/zip</dc:format>
      <dc:format>downloadable_files_count: 1</dc:format>
      <dc:publisher>Jan Koco&#324;</dc:publisher>
    </oai_dc:dc>
  </metadata>
</record>
