<record xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <header>
    <identifier>oai:lindat.mff.cuni.cz:11234/1-1970</identifier>
    <datestamp>2017-11-09T14:21:55Z</datestamp>
    <setSpec>hdl_11858_00-097C-0000-0001-486F-D</setSpec>
    <setSpec>hdl_11858_00-097C-0000-0001-4877-A</setSpec>
  </header>
  <metadata>
    <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:doc="http://www.lyncode.com/xoai" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
      <dc:title>Slavic Forest, Norwegian Wood (scripts)</dc:title>
      <dc:creator>Rosa, Rudolf</dc:creator>
      <dc:creator>Zeman, Daniel</dc:creator>
      <dc:creator>Mare&#269;ek, David</dc:creator>
      <dc:creator>&#381;abokrtsk&#253;, Zden&#283;k</dc:creator>
      <dc:subject>parsing</dc:subject>
      <dc:subject>dependency parser</dc:subject>
      <dc:subject>universal dependencies</dc:subject>
      <dc:subject>cross-lingual parsing</dc:subject>
      <dc:description>Tools and scripts used to create the cross-lingual parsing models submitted to VarDial 2017 shared task (https://bitbucket.org/hy-crossNLP/vardial2017), as described in the linked paper. The trained UDPipe models themselves are published in a separate submission (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1971).&#13;
&#13;
For each source (SS, e.g. sl) and target (TT, e.g. hr) language,&#13;
you need to add the following into this directory:&#13;
&#13;
- treebanks (Universal Dependencies v1.4):&#13;
SS-ud-train.conllu&#13;
TT-ud-predPoS-dev.conllu&#13;
&#13;
- parallel data (OpenSubtitles from Opus):&#13;
OpenSubtitles2016.SS-TT.SS&#13;
OpenSubtitles2016.SS-TT.TT&#13;
!!! If they are originally called ...TT-SS... instead of ...SS-TT...,&#13;
you need to symlink them (or move, or copy) !!!&#13;
&#13;
- target tagging model&#13;
TT.tagger.udpipe&#13;
&#13;
All of these can be obtained from https://bitbucket.org/hy-crossNLP/vardial2017&#13;
&#13;
&#13;
You also need to have:&#13;
- Bash&#13;
- Perl 5&#13;
- Python 3&#13;
- word2vec (https://code.google.com/archive/p/word2vec/); we used rev 41 from 15th Sep 2014&#13;
- udpipe (https://github.com/ufal/udpipe); we used commit 3e65d69 from 3rd Jan 2017&#13;
- Treex (https://github.com/ufal/treex); we used commit d27ee8a from 21st Dec 2016&#13;
&#13;
&#13;
The most basic setup is the sl-hr one (train_sl-hr.sh):&#13;
- normalization of deprels&#13;
- 1:1 word-alignment of parallel data with Monolingual Greedy Aligner&#13;
- simple word-by-word translation of source treebank&#13;
- pre-training of target word embeddings&#13;
- simplification of morpho feats (use only Case)&#13;
- and finally, training and evaluating the parser&#13;
&#13;
Both da+sv-no (train_ds-no.sh) and cs-sk (train_cs-sk.sh) add some cross-tagging, which seems to be useful only in&#13;
specific cases (see paper for details).&#13;
Moreover, cs-sk also adds more morpho features, selecting those that&#13;
seem to be very often shared in parallel data.&#13;
&#13;
The whole pipeline takes tens of hours to run, and uses several GB of RAM, so make sure to use a powerful computer.</dc:description>
      <dc:date>2017-01-28</dc:date>
      <dc:type>toolService</dc:type>
      <dc:identifier>http://hdl.handle.net/11234/1-1970</dc:identifier>
      <dc:language>ces</dc:language>
      <dc:language>slk</dc:language>
      <dc:language>slv</dc:language>
      <dc:language>hrv</dc:language>
      <dc:language>dan</dc:language>
      <dc:language>swe</dc:language>
      <dc:language>nor</dc:language>
      <dc:relation>info:eu-repo/grantAgreement/EC/H2020/644402</dc:relation>
      <dc:relation>http://web.science.mq.edu.au/~smalmasi/vardial4/pdf/VarDial26.pdf</dc:relation>
      <dc:rights>GNU General Public License 2 or later (GPL-2.0)</dc:rights>
      <dc:rights>http://opensource.org/licenses/GPL-2.0</dc:rights>
      <dc:rights>PUB</dc:rights>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>application/octet-stream</dc:format>
      <dc:format>text/plain; charset=utf-8</dc:format>
      <dc:format>downloadable_files_count: 11</dc:format>
      <dc:publisher>Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics (UFAL)</dc:publisher>
    </oai_dc:dc>
  </metadata>
</record>
